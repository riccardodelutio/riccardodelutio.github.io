<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<meta name=author content="Riccardo de Lutio">
<meta name=description content="We introduce a novel formulation for guided super-resolution. Its core is a differentiable optimisation layer that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich contextual information from the guide image, while the explicit graph optimisation within the architecture guarantees exact fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the prediction, our method differs from state-of-the-art deep architectures for guided super-resolution, which produce targets that, when downsampled, will only approximately reproduce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph connectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields. By taking advantage of the sparse graph connectivity, it becomes possible to propagate gradients through the optimisation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quantitative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen during training.">
<link rel=alternate hreflang=en-us href=https://example.com/publication/learning-graph/>
<meta name=theme-color content="#1565c0">
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=/css/wowchemy.246129d782c938a644fe2d653d8a976f.css>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://example.com/publication/learning-graph/>
<meta property="twitter:card" content="summary_large_image">
<meta property="og:site_name" content="Riccardo de Lutio">
<meta property="og:url" content="https://example.com/publication/learning-graph/">
<meta property="og:title" content="Learning Graph Regularisation for Guided Super-Resolution | Riccardo de Lutio">
<meta property="og:description" content="We introduce a novel formulation for guided super-resolution. Its core is a differentiable optimisation layer that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich contextual information from the guide image, while the explicit graph optimisation within the architecture guarantees exact fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the prediction, our method differs from state-of-the-art deep architectures for guided super-resolution, which produce targets that, when downsampled, will only approximately reproduce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph connectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields. By taking advantage of the sparse graph connectivity, it becomes possible to propagate gradients through the optimisation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quantitative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen during training."><meta property="og:image" content="https://example.com/publication/learning-graph/featured.png">
<meta property="twitter:image" content="https://example.com/publication/learning-graph/featured.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2022-02-03T00:00:00+00:00">
<meta property="article:modified_time" content="2022-02-03T00:00:00+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://example.com/publication/learning-graph/"},"headline":"Learning Graph Regularisation for Guided Super-Resolution","image":["https://example.com/publication/learning-graph/featured.png"],"datePublished":"2022-02-03T00:00:00Z","dateModified":"2022-02-03T00:00:00Z","author":{"@type":"Person","name":"Riccardo de Lutio"},"publisher":{"@type":"Organization","name":"Riccardo de Lutio","logo":{"@type":"ImageObject","url":"https://example.com/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_192x192_fill_lanczos_center_3.png"}},"description":"We introduce a novel formulation for guided super-resolution. Its core is a differentiable optimisation layer that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich contextual information from the guide image, while the explicit graph optimisation within the architecture guarantees exact fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the prediction, our method differs from state-of-the-art deep architectures for guided super-resolution, which produce targets that, when downsampled, will only approximately reproduce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph connectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields. By taking advantage of the sparse graph connectivity, it becomes possible to propagate gradients through the optimisation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quantitative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen during training."}</script>
<title>Learning Graph Regularisation for Guided Super-Resolution | Riccardo de Lutio</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=f4038d2098b9c24d74d34b678c32e34f>
<script src=/js/wowchemy-init.min.8f76bdc9e086322ed5147724ebba3d06.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Riccardo de Lutio</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Riccardo de Lutio</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#publications><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#experience><span>Experience</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#education><span>Education</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#teaching><span>Teaching</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#accomplishments><span>Additional</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class=nav-item>
<a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a>
</li>
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>Learning Graph Regularisation for Guided Super-Resolution</h1>
<div class=article-metadata>
<div>
<span class=author-highlighted>
Riccardo de Lutio</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>
Alexander Becker</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>
Stefano D'Aronco</span>, <span>
Stefania Russo</span>, <span>
Jan D. Wegner</span>, <span>
Konrad Schindler</span>
</div>
<span class=article-date>
February 2022
</span>
</div>
<div class="btn-links mb-3">
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/learning-graph/cite.bib>
Cite
</a>
</div>
</div>
<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:388px>
<div style=position:relative>
<img src=/publication/learning-graph/featured_hu1f64035bf262ee9fb5231c7f0b694b10_703179_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=388 alt class=featured-image>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>We introduce a novel formulation for guided super-resolution. Its core is a differentiable optimisation layer that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich contextual information from the guide image, while the explicit graph optimisation within the architecture guarantees exact fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the prediction, our method differs from state-of-the-art deep architectures for guided super-resolution, which produce targets that, when downsampled, will only approximately reproduce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph connectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields. By taking advantage of the sparse graph connectivity, it becomes possible to propagate gradients through the optimisation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quantitative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen during training.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#1>
Conference paper
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">In <em>Under Review</em></div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=share-box>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://example.com/publication/learning-graph/&text=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://example.com/publication/learning-graph/&t=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution&body=https://example.com/publication/learning-graph/" target=_blank rel=noopener class=share-btn-email aria-label=envelope>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://example.com/publication/learning-graph/&title=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution%20https://example.com/publication/learning-graph/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://example.com/publication/learning-graph/&title=Learning%20Graph%20Regularisation%20for%20Guided%20Super-Resolution" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="media author-card content-widget-hr">
<a href=https://example.com/><img class="avatar mr-3 avatar-circle" src=/authors/riccardo-delutio/avatar_hu1e05d761e9c47889a31c135c873c3e13_1073212_270x270_fill_q75_lanczos_center.jpg alt="Riccardo de Lutio"></a>
<div class=media-body>
<h5 class=card-title><a href=https://example.com/>Riccardo de Lutio</a></h5>
<h6 class=card-subtitle>PhD Candidate</h6>
<p class=card-text>I am a PhD student in the EcoVision Lab, Photogrammetry and Remote Sensing group at ETH. I focus on super-resolution and biodiversity monitoring.</p>
<ul class=network-icon aria-hidden=true>
<li>
<a href=mailto:rdelutio@ethz.ch>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href=https://twitter.com/RdeLutio target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://scholar.google.ch/citations?user=fBP5RngAAAAJ&hl=en" target=_blank rel=noopener>
<i class="fas fa-graduation-cap"></i>
</a>
</li>
<li>
<a href=https://github.com/riccardodelutio target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/riccardodelutio/ target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.247fd8f54253895301106e3006f53f38.js></script>
</body>
</html>