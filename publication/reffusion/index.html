<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<meta name=author content="Riccardo de Lutio">
<meta name=description content="Neural reconstruction approaches are rapidly emerging as the preferred representation for 3D scenes, but their limited editability is still posing a challenge. In this work, we propose an approach for 3D scene inpainting -- the task of coherently replacing parts of the reconstructed scene with desired content. Scene inpainting is an inherently ill-posed task as there exist many solutions that plausibly replace the missing content. A good inpainting method should therefore not only enable high-quality synthesis but also a high degree of control. Based on this observation, we focus on enabling explicit control over the inpainted content and leverage a reference image as an efficient means to achieve this goal. Specifically, we introduce RefFusion, a novel 3D inpainting method based on a multi-scale personalization of an image inpainting diffusion model to the given reference view. The personalization effectively adapts the prior distribution to the target scene, resulting in a lower variance of score distillation objective and hence significantly sharper details. Our framework achieves state-of-the-art results for object removal while maintaining high controllability. We further demonstrate the generality of our formulation on other downstream tasks such as object insertion, scene outpainting, and sparse view reconstruction.">
<link rel=alternate hreflang=en-us href=https://riccardodelutio.github.io/publication/reffusion/>
<meta name=theme-color content="#1565c0">
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=/css/wowchemy.246129d782c938a644fe2d653d8a976f.css>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://riccardodelutio.github.io/publication/reffusion/>
<meta property="twitter:card" content="summary_large_image">
<meta property="og:site_name" content="Riccardo de Lutio">
<meta property="og:url" content="https://riccardodelutio.github.io/publication/reffusion/">
<meta property="og:title" content="RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting | Riccardo de Lutio">
<meta property="og:description" content="Neural reconstruction approaches are rapidly emerging as the preferred representation for 3D scenes, but their limited editability is still posing a challenge. In this work, we propose an approach for 3D scene inpainting -- the task of coherently replacing parts of the reconstructed scene with desired content. Scene inpainting is an inherently ill-posed task as there exist many solutions that plausibly replace the missing content. A good inpainting method should therefore not only enable high-quality synthesis but also a high degree of control. Based on this observation, we focus on enabling explicit control over the inpainted content and leverage a reference image as an efficient means to achieve this goal. Specifically, we introduce RefFusion, a novel 3D inpainting method based on a multi-scale personalization of an image inpainting diffusion model to the given reference view. The personalization effectively adapts the prior distribution to the target scene, resulting in a lower variance of score distillation objective and hence significantly sharper details. Our framework achieves state-of-the-art results for object removal while maintaining high controllability. We further demonstrate the generality of our formulation on other downstream tasks such as object insertion, scene outpainting, and sparse view reconstruction."><meta property="og:image" content="https://riccardodelutio.github.io/publication/reffusion/featured.jpg">
<meta property="twitter:image" content="https://riccardodelutio.github.io/publication/reffusion/featured.jpg"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2024-04-16T00:00:00+00:00">
<meta property="article:modified_time" content="2024-04-16T00:00:00+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://riccardodelutio.github.io/publication/reffusion/"},"headline":"RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting","image":["https://riccardodelutio.github.io/publication/reffusion/featured.jpg"],"datePublished":"2024-04-16T00:00:00Z","dateModified":"2024-04-16T00:00:00Z","author":{"@type":"Person","name":"Ashkan Mirzaei"},"publisher":{"@type":"Organization","name":"Riccardo de Lutio","logo":{"@type":"ImageObject","url":"https://riccardodelutio.github.io/media/icon_hua74a7bbaacca6c95eb1212ba4a217917_34868_192x192_fill_lanczos_center_3.png"}},"description":"Neural reconstruction approaches are rapidly emerging as the preferred representation for 3D scenes, but their limited editability is still posing a challenge. In this work, we propose an approach for 3D scene inpainting -- the task of coherently replacing parts of the reconstructed scene with desired content. Scene inpainting is an inherently ill-posed task as there exist many solutions that plausibly replace the missing content. A good inpainting method should therefore not only enable high-quality synthesis but also a high degree of control. Based on this observation, we focus on enabling explicit control over the inpainted content and leverage a reference image as an efficient means to achieve this goal. Specifically, we introduce RefFusion, a novel 3D inpainting method based on a multi-scale personalization of an image inpainting diffusion model to the given reference view. The personalization effectively adapts the prior distribution to the target scene, resulting in a lower variance of score distillation objective and hence significantly sharper details. Our framework achieves state-of-the-art results for object removal while maintaining high controllability. We further demonstrate the generality of our formulation on other downstream tasks such as object insertion, scene outpainting, and sparse view reconstruction."}</script>
<title>RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting | Riccardo de Lutio</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=7d6ce2052cc0319521352f632ef70f78>
<script src=/js/wowchemy-init.min.8f76bdc9e086322ed5147724ebba3d06.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Riccardo de Lutio</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Riccardo de Lutio</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#publications><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#experience><span>Experience</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#education><span>Education</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#teaching><span>Teaching</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#accomplishments><span>Additional</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class=nav-item>
<a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a>
</li>
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting</h1>
<div class=article-metadata>
<div>
<span>
Ashkan Mirzaei</span>, <span class=author-highlighted>
Riccardo de Lutio</span>, <span>
Seung Wook Kim</span>, <span>
David Acuna</span>, <span>
Jonathan Kelly</span>, <span>
Sanja Fidler</span>, <span>
Igor Gilitschenski</span>, <span>
Zan Gojcic</span>
</div>
<span class=article-date>
April 2024
</span>
</div>
<div class="btn-links mb-3">
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/pdf/2404.10765 target=_blank rel=noopener>
PDF
</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/reffusion/cite.bib>
Cite
</a>
</div>
</div>
<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:248px>
<div style=position:relative>
<img src=/publication/reffusion/featured_hu9cfc2ad6f7a9db0573594128b9f1ddb1_4204931_720x2500_fit_q75_h2_lanczos.webp width=720 height=248 alt class=featured-image>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>Neural reconstruction approaches are rapidly emerging as the preferred representation for 3D scenes, but their limited editability is still posing a challenge. In this work, we propose an approach for 3D scene inpainting &ndash; the task of coherently replacing parts of the reconstructed scene with desired content. Scene inpainting is an inherently ill-posed task as there exist many solutions that plausibly replace the missing content. A good inpainting method should therefore not only enable high-quality synthesis but also a high degree of control. Based on this observation, we focus on enabling explicit control over the inpainted content and leverage a reference image as an efficient means to achieve this goal. Specifically, we introduce RefFusion, a novel 3D inpainting method based on a multi-scale personalization of an image inpainting diffusion model to the given reference view. The personalization effectively adapts the prior distribution to the target scene, resulting in a lower variance of score distillation objective and hence significantly sharper details. Our framework achieves state-of-the-art results for object removal while maintaining high controllability. We further demonstrate the generality of our formulation on other downstream tasks such as object insertion, scene outpainting, and sparse view reconstruction.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#3>
Preprint
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">In <em>arXiv</em></div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=share-box>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://riccardodelutio.github.io/publication/reffusion/&text=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://riccardodelutio.github.io/publication/reffusion/&t=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting&body=https://riccardodelutio.github.io/publication/reffusion/" target=_blank rel=noopener class=share-btn-email aria-label=envelope>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://riccardodelutio.github.io/publication/reffusion/&title=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting%20https://riccardodelutio.github.io/publication/reffusion/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://riccardodelutio.github.io/publication/reffusion/&title=RefFusion:%20Reference%20Adapted%20Diffusion%20Models%20for%203D%20Scene%20Inpainting" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="media author-card content-widget-hr">
<a href=https://riccardodelutio.github.io/><img class="avatar mr-3 avatar-circle" src=/authors/riccardo-delutio/avatar_hu1e05d761e9c47889a31c135c873c3e13_1073212_270x270_fill_q75_lanczos_center.jpg alt="Riccardo de Lutio"></a>
<div class=media-body>
<h5 class=card-title><a href=https://riccardodelutio.github.io/>Riccardo de Lutio</a></h5>
<h6 class=card-subtitle>Research Scientist</h6>
<p class=card-text>I am a Research Scientist at NVIDIA in the Toronto AI Lab, generally interested in 3D computer vision and neural reconstruction.</p>
<ul class=network-icon aria-hidden=true>
<li>
<a href=mailto:rdelutio@nvidia.com>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href=https://twitter.com/RdeLutio target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://scholar.google.ch/citations?user=fBP5RngAAAAJ&hl=en" target=_blank rel=noopener>
<i class="fas fa-graduation-cap"></i>
</a>
</li>
<li>
<a href=https://github.com/riccardodelutio target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/riccardodelutio/ target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
© 2025 Riccardo de Lutio
</p>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.247fd8f54253895301106e3006f53f38.js></script>
</body>
</html>